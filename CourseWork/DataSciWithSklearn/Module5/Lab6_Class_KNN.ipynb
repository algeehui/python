{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module5- Lab6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you'll flex your understanding of Isomap and KNeighbors, as well as practice splitting your data for testing and evaluation by taking your Module4/Module4 - Lab4.py lab to the next level. If you haven't been able to complete module four's labs or haven't fully understood them, take a moment to re-do them all before proceeding.\n",
    "\n",
    "This assignment was engineered to be truer to the life of a data scientist by being more challenging than previous ones, so do not be disheartened. If data explorers only needed to drop their observations into black-box algorithms without investing time to toggle parameters, and experiment and understand what those algorithms were truly doing to their data, they wouldn't be valued as much.\n",
    "\n",
    "In module four's fourth lab assignment, you explored using isomap, an indispensable tool to have while working with non-linear datasets. Your goal this time is to train the KNeighborsClassifier to identify what direction a face is pointing towards: either up, down, left, or right.\n",
    "\n",
    "\n",
    "\n",
    "This data takes the form of image samples that have been transformed either using PCA to reduce their linear dimensionality, or isomap to non-linearly do similar. Start by reviewing your lab work in the Module4/Module4 - Lab5.ipynb file before opening up the /Module5/Module5 - Lab6.ipynb starter code. You will need access to the face_data.mat file from Module four, as well as the new Module5/face_labels.csv file.\n",
    "\n",
    "Add in the Module4/Module4 - Lab4.ipynb cell blocks / code responsible for: loading up the .mat file, properly rotating its images, and storing the whole thing into a Pandas dataframe object.\n",
    "Load into a dataframe your classifications faces_labels.csv file. Make sure your dataframe and your .csv file align properly and start from the same values! This classification dataframe only has a single column in it, so create a series (a slice) that selects only that column and save it as label.\n",
    "Do your train_test_split just as directed in the reading. Set random_state=7 as documented. Your variables should be: data_train, data_test, label_train, and label_test.\n",
    "Fill out the code for PCA, Isomap, and KNeighborsClassifier. Both PCA and Isomap should be reducing your training data's dimensionality down to 2D. You're free to experiment with different K values for KNeighborsClassifier.\n",
    "Predict the accuracy of the test dataset / test label using .score() and print it out.\n",
    "Answer the questions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib.style.use('ggplot') # Look Pretty\n",
    "\n",
    "\n",
    "# Leave this alone until indicated:\n",
    "Test_PCA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Convenience Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is for your visualization convenience only. You aren't expected to know how to put this together yourself, although you should be able to follow the code by now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Plot2DBoundary(model, DTrain, LTrain, DTest, LTest):\n",
    "    # The dots are training samples (img not drawn), and the pics are testing samples (images drawn)\n",
    "    # Play around with the K values. This is very controlled dataset so it should be able to get perfect classification on testing entries\n",
    "    # Play with the K for isomap, play with the K for neighbors. \n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('Transformed Boundary, Image Space -> 2D')\n",
    "\n",
    "    padding = 0.1   # Zoom out\n",
    "    resolution = 1  # Don't get too detailed; smaller values (finer rez) will take longer to compute\n",
    "    colors = ['blue','green','orange','red']\n",
    "\n",
    "\n",
    "    # ------\n",
    "\n",
    "    # Calculate the boundaries of the mesh grid. The mesh grid is\n",
    "    # a standard grid (think graph paper), where each point will be\n",
    "    # sent to the classifier (KNeighbors) to predict what class it\n",
    "    # belongs to. This is why KNeighbors has to be trained against\n",
    "    # 2D data, so we can produce this countour. Once we have the \n",
    "    # label for each point on the grid, we can color it appropriately\n",
    "    # and plot it.\n",
    "    x_min, x_max = DTrain[:, 0].min(), DTrain[:, 0].max()\n",
    "    y_min, y_max = DTrain[:, 1].min(), DTrain[:, 1].max()\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= x_range * padding\n",
    "    y_min -= y_range * padding\n",
    "    x_max += x_range * padding\n",
    "    y_max += y_range * padding\n",
    "\n",
    "    # Using the boundaries, actually make the 2D Grid Matrix:\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                         np.arange(y_min, y_max, resolution))\n",
    "\n",
    "    # What class does the classifier say about each spot on the chart?\n",
    "    # The values stored in the matrix are the predictions of the model\n",
    "    # at said location:\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the mesh grid as a filled contour plot:\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.terrain, z=-100)\n",
    "\n",
    "\n",
    "    # ------\n",
    "\n",
    "    # When plotting the testing images, used to validate if the algorithm\n",
    "    # is functioning correctly, size them as 5% of the overall chart size\n",
    "    x_size = x_range * 0.05\n",
    "    y_size = y_range * 0.05\n",
    "\n",
    "    # First, plot the images in your TEST dataset\n",
    "    img_num = 0\n",
    "    for index in LTest.index:\n",
    "        # DTest is a regular NDArray, so you'll iterate over that 1 at a time.\n",
    "        x0, y0 = DTest[img_num,0]-x_size/2., DTest[img_num,1]-y_size/2.\n",
    "        x1, y1 = DTest[img_num,0]+x_size/2., DTest[img_num,1]+y_size/2.\n",
    "\n",
    "        # DTest = our images isomap-transformed into 2D. But we still want\n",
    "        # to plot the original image, so we look to the original, untouched\n",
    "        # dataset (at index) to get the pixels:\n",
    "        img = df.iloc[index,:].reshape(num_pixels, num_pixels)\n",
    "        ax.imshow(img,\n",
    "                  aspect='auto',\n",
    "                  cmap=plt.cm.gray,\n",
    "                  interpolation='nearest',\n",
    "                  zorder=100000,\n",
    "                  extent=(x0, x1, y0, y1),\n",
    "                  alpha=0.8)\n",
    "        img_num += 1\n",
    "\n",
    "\n",
    "    # Plot your TRAINING points as well... as points rather than as images\n",
    "    for label in range(len(np.unique(LTrain))):\n",
    "        indices = np.where(LTrain == label)\n",
    "        ax.scatter(DTrain[indices, 0], DTrain[indices, 1], c=colors[label], alpha=0.8, marker='o')\n",
    "\n",
    "    # Plot\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same code from Module4/assignment4.ipynb to load up the `face_data.mat` file into a dataframe called `df`. Be sure to calculate the `num_pixels` value, and to rotate the images to being right-side-up instead of sideways. This was demonstrated in the [Lab Assignment 4](https://github.com/authman/DAT210x/blob/master/Module4/assignment4.ipynb) code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('../Module4/Datasets/face_data.mat')\n",
    "df = pd.DataFrame(mat['images']).T\n",
    "num_images, num_pixels = df.shape\n",
    "num_pixels = int(math.sqrt(num_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Rotate the pictures, so we don't have to crane our necks:\n",
    "for i in range(num_images):\n",
    "    df.loc[i,:] = df.loc[i,:].reshape(num_pixels, num_pixels).T.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.05671</td>\n",
       "      <td>0.192279</td>\n",
       "      <td>0.380607</td>\n",
       "      <td>0.504733</td>\n",
       "      <td>0.51492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3         4        5         6         7     \\\n",
       "0  0.016176   0.0   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "1  0.016176   0.0   0.0   0.0  0.007062  0.05671  0.192279  0.380607   \n",
       "2  0.016176   0.0   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "\n",
       "       8        9     ...       4086  4087  4088  4089  4090  4091  4092  \\\n",
       "0  0.000000  0.00000  ...   0.000781   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1  0.504733  0.51492  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2  0.000000  0.00000  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   4093  4094  4095  \n",
       "0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0  \n",
       "\n",
       "[3 rows x 4096 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(698, 4096)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up your face_labels dataset. It only has a single column, and you're only interested in that single column. You will have to slice the  column out so that you have access to it as a \"Series\" rather than as a \"Dataframe\". This was discussed in the the \"Slicin'\" lecture of the  \"Manipulating Data\" reading on the course website. Use an appropriate indexer to take care of that. Be sure to print out the labels and compare what you see to the raw `face_labels.csv` so you know you loaded it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(698,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(r'Datasets/face_labels.csv', header=None)\n",
    "y = np.ravel(y)\n",
    "np.shape(y)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do `train_test_split`. Use the same code as on the EdX platform in the reading material, but set the random_state=7 for reproducibility, and the test_size to 0.15 (150%). Your labels are actually passed in as a series (instead of as an NDArray) so that you can access their underlying indices later on. This is necessary so you can find your samples in the original dataframe. The convenience methods we've written for you that handle drawing expect this, so that they can plot your testing data as images rather than as points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, y, test_size=0.15, random_state=7)\n",
    "data_train, label_train, data_test, label_test = train_test_split(df.values, y, test_size=0.15, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if Test_PCA:\n",
    "    # INFO: PCA is used *before* KNeighbors to simplify your high dimensionality\n",
    "    # image samples down to just 2 principal components! A lot of information\n",
    "    # (variance) is lost during the process, as I'm sure you can imagine. But\n",
    "    # you have to drop the dimension down to two, otherwise you wouldn't be able\n",
    "    # to visualize a 2D decision surface / boundary. In the wild, you'd probably\n",
    "    # leave in a lot more dimensions, which is better for higher accuracy, but\n",
    "    # worse for visualizing the decision boundary;\n",
    "    #\n",
    "    # Your model should only be trained (fit) against the training data (data_train)\n",
    "    # Once you've done this, you need use the model to transform both data_train\n",
    "    # and data_test from their original high-D image feature space, down to 2D\n",
    "\n",
    "\n",
    "    # TODO: Implement PCA here. ONLY train against your training data, but\n",
    "    # transform both your training + test data, storing the results back into\n",
    "    # data_train, and data_test.\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    T = pca.fit(X_train)\n",
    "    data_train = T.transform(X_train)\n",
    "    data_test = T.transform(X_test)\n",
    "\n",
    "else:\n",
    "    # INFO: Isomap is used *before* KNeighbors to simplify your high dimensionality\n",
    "    # image samples down to just 2 components! A lot of information has been is\n",
    "    # lost during the process, as I'm sure you can imagine. But if you have\n",
    "    # non-linear data that can be represented on a 2D manifold, you probably will\n",
    "    # be left with a far superior dataset to use for classification. Plus by\n",
    "    # having the images in 2D space, you can plot them as well as visualize a 2D\n",
    "    # decision surface / boundary. In the wild, you'd probably leave in a lot more\n",
    "    # dimensions, which is better for higher accuracy, but worse for visualizing the\n",
    "    # decision boundary;\n",
    "    \n",
    "    # Your model should only be trained (fit) against the training data (data_train)\n",
    "    # Once you've done this, you need use the model to transform both data_train\n",
    "    # and data_test from their original high-D image feature space, down to 2D\n",
    "\n",
    "    \n",
    "    # TODO: Implement Isomap here. ONLY train against your training data, but\n",
    "    # transform both your training + test data, storing the results back into\n",
    "    # data_train, and data_test.\n",
    "    \n",
    "    from sklearn.manifold import Isomap\n",
    "    isomap = Isomap(n_components=2, n_neighbors=5)\n",
    "    T = isomap.fit(X_train)\n",
    "    data_train = T.transform(X_train)\n",
    "    data_test = T.transform(X_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `KNeighborsClassifier` here. You can use any K value from 1 through 20, so play around with it and attempt to get good accuracy. Fit the classifier against your training data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and display the accuracy of the testing set (data_test and label_test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  0.9809523809523809\n",
      "2 :  0.9809523809523809\n",
      "3 :  0.9714285714285714\n",
      "4 :  0.9904761904761905\n",
      "5 :  0.9714285714285714\n",
      "6 :  0.9619047619047619\n",
      "7 :  0.9523809523809523\n",
      "8 :  0.9714285714285714\n",
      "9 :  0.9809523809523809\n",
      "10 :  0.9809523809523809\n",
      "11 :  0.9809523809523809\n",
      "12 :  0.9809523809523809\n",
      "13 :  0.9714285714285714\n",
      "14 :  0.9714285714285714\n",
      "15 :  0.9714285714285714\n",
      "16 :  0.9619047619047619\n",
      "17 :  0.9619047619047619\n",
      "18 :  0.9714285714285714\n",
      "19 :  0.9714285714285714\n",
      "20 :  0.9619047619047619\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,21):\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(i,': ', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4\n",
    "model = KNeighborsClassifier(n_neighbors=i)\n",
    "model.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's chart the combined decision boundary, the training data as 2D plots, and the testing data as small images so we can visually validate performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 4096)\n",
      "(593,)\n",
      "(105, 4096)\n",
      "(105,)\n"
     ]
    }
   ],
   "source": [
    "data_train = X_train\n",
    "label_train = y_train\n",
    "data_test = X_test\n",
    "label_test = y_test\n",
    "print(data_train.shape)\n",
    "print(label_train.shape)\n",
    "\n",
    "print(data_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "query data dimension must match training data dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-b2d70949457a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPlot2DBoundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-a310aa77165c>\u001b[0m in \u001b[0;36mPlot2DBoundary\u001b[1;34m(model, DTrain, LTrain, DTest, LTest)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# The values stored in the matrix are the predictions of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# at said location:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[0;32m    384\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 385\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m             )\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\neighbors\\binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors.kd_tree.BinaryTree.query\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: query data dimension must match training data dimension"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAF0xJREFUeJzt3H20JHV95/H3RxCIPCtjYmYGwQWiBJOgE3xgo7hiDnAUTNajcBajLoqrooniAzGJMWh2TzSJqxuMonF9CiK4UUdE0SguxhWXcVEiKDoCwgSQQWEUUBH87h9V1ymae+fW3Mdxfu/XOX1OV9Wvq7796+pPV/+qq1NVSJK2f/dZ7gIkSUvDwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBvw1K8jtJ1ie5LcmTl7ueoSQHJPmF+C1vkg1JjljuOqRthYHf68N16vazJD8aTP+nJS7n9cCbqmq3qjpvibc9L33ITvXdLUnOS7JyuetaSkmOTHLNctcxmyT7JvlwkpuTbEryr0meudx1LbQkv5Lk7CQ39M/z80l+e7D8uUnuHrzfr07yriQHLmfdi8HA7/XhultV7QZcCzxlMO8fJ9sn2XERy3kwcPlcHrjIdY11dN+PDwK+B7x5mevZKttIHy6FfwSuAvYFHgA8C7hpWSuaRZJfnsPDdgMuBg4F7g+cBXw8yf0GbT7f77N7AkcCPwXWJXnYPEvetlSVt4kbcA1w5MS81wMfBD4A/BB4NvAYuh3pVuAG4C3Affv2OwIFPB9YD9wCvGWwvoOAi4BNwM3AWYNt/wz4EXAbsAOwCjgP+D7wLeA/z1LX64Gz+3m3AV8F/h3wp8BGug+0Iwfr2Av4n/1z2ACcDtynX7YD8Ca64P42cEq328zYdxuAIwbTxwJXTGzr/X0d1wB/DGTwXN49aHvAcFvAvwB/Afyf/rl+Erj/YPmzge/0/XnasJaRr9UL+9dqPfB24K8mntsngFNG7D9HAtdM1H16v/3bgY/QBewHgB8AXwL2HbT/u772HwCXAI8dLLtf33+3Alf0z3O4rVXAh/v+vRp40Rbq/DFwyAzLDuj75HnA9f3tpYPlM/Znv/zhwD/T7bM3Aq/s598HeHW/L91Mt5/uvRXvzU/3230+sOc83uO3A7/Z338u8Llp2nwSOHs5s2ihb8tewLZ4Y+bAvxN4Sr/T/hLw28Cj+sB4CPDNqUAYhMhH6Y4a9ut3/iP75ecCr+rXtQtw+GBbk6H5BeB/9O0e0b9RHr+Ful5P94FxZF/HWf2b/7R++gXAtwbrPw94ax8mvwJ8GTipX3YK3beNVXQhdREjAx/YlS6c3jVYfhbwT8DufZ+tB541eC7vHrSdLvC/BRzY1/p54PX9sofTfbgdDuxMF0B3DWoZ81p9Eti778PHAtex+YPvl4E7gH1G7D/TBf43++3uDXwDuBJ4wuD1eceg/TPpjkR37PeRfwN27pf9NfBZug/O1cDXprZF9+H8FbpA3anvv2uAJ85Q5+f6PnwGsHpi2VTgv6/v69+k+9Af0597At8F/rB/LfYADuuXvZxuf15Jtz//A/C+rXhv3hf4Pbr31Sa6bylHTr1OI9expn8td++nZwr8k4F/W+48WsjbshewLd6YOfA/O8vjXg6c29+fCpFHD5b/E/Dy/v5ZwN8DK6dZzzA096f7ernrYPkbgXfOVFc/7xOD6d/r3xxT4bV3X9tu/RvvR1OB0i9/JvDp/v5FwHMHy45h9sC/je7I765++tf7Zfft5x00aP8i4J8Hdb97sGy6wD9tMP0S4Lz+/unA+wfLdgPuZvDBOeK1etxEm28CT+jv/xGwduT+M13gv2ow/WbgYxOvz7oZ1hW6bzNTfXgtgwAH/gubA/9w4KqJx/8Zgw+TiWX3B95A903hZ8D/Ax457HvggEH7vwXePqI/n7mF5/Mt+oOVfno18BO2IrAHj13Rvy6X0n2ze8GIx+xJdwDzisG8mQL/ycCPtraubfnmGP7WuW44keShST6e5MYkP6ALnX0mHnPj4P4ddEEEcCpdAK7rT5Y9a4Zt/ipwc1XdPpj3Hbqgnrau3ncH938EbKyqnw2m6Wt5MN1R2HeT3JrkVuAMuiPaqe0P1/+dGeocenJV7dWv96XARUlWAA+kOwodrmPyucxmpv68R51VdRvdNypg9Gs12Y/vBU7s759Id7Q7V5Ovx+T01PMgySuTfCPJJrqhwF0HtT5oos7h/QcD+069jv1r+Uq6b233UlXfr6pXVtXBdK/35XTDQUOTr/2v9jVuqT9X031zm86+wMcG9f0r3QfLAycbJvnU4ETqM6ZZ1810w5Vfofvw2m+GbU6tb1fg48BFVfXGLbXtrWSwD20PDPytUxPTb6f7Sn1AVe0BvIbuiGz2FVXdUFXPraoH0R3lnplk/2maXg/s0++sU/al+5o/U11b4zq64Lx/Ve3V3/aoqt/ol99A9wYebnuUqrq7qs6l288OpzsheDddMA3XN/VcbqcbPpgybVDN4B51JtmNLgSmjHmtJvvxfcDvJzmU7hzIx7ainjlJ8gTgZcB/pBu22ZvuG9NUrTfSDa9NGb4219EN1e01uO1eVU+ZbbtVtRH4G2B1kj1nWP++dPsjbLk/r6Prr+lsAJ40UeMuVXXjZMOq+t3a/MOJD07NT/JrSf6S7pv4m+hC/yFV9aqZnl+SXeiGga6iO1czxlPphry2Gwb+/OxON1Rye382//ljH5jk6YOfK95KFzZ3T7arqquBdcB/TbJzkt8CnkM3djlvVXUd8L+Bv06yR5L79L+1f1zf5Bzgj5KsTPIAujHlUdL5fbp++kZV/RT4UP9cdus/4F5KN84P3ZHa45OsTrIX3TmHsc4FjkvymCQ70w0PDQN8q1+rqvpOX9N76IYrfjx4bu9P8s6tqG+s3emGvW6m+wb4Wroj/CnnAK9OsleSVXQHC1O+CNyZ5NQkuyTZIcnDkzxyug0leUOSX+/b7UF3bucbVbVp0OzPkvxSkofT/YpnKni31J9r6b5pnJJkp36/Oqxf9ja613/fvoYHJjl2bOckeS/dENnuwFOr6req6r/3H1gzPWYnuuHUTcBzqh+vmaHtDkkekuStwL8HXje2tl8EBv78nEr3Jvgh3RHPB7fc/B4eBVyS5Ha6nfFFVXXtDG2fQXei8ka6wHx1VV0456rv7US6ULmCbgjhXDYfXf898Bm6r96X9NufzSeS3Eb3K5O/AE6sqm/0y15Id5L5aroPmvfQDZ1Ad9L0w/22/i9dcIxSVZfRnSQ8h+4bw43cc/hnrq/Ve+hOCE8O56ymO/m40M6n+3XLt+iOYH9A9+1lyp/TDQddA3yK7vn+BKCq7qI7x3JYv/xmuue6xwzb2o3NJz+/TTdc89SJNv9Cd1T8KeC/VdVn+/kz9mf/gfEkum8pN9GdC3l8v/hv6V7nzyT5Id0vrn7+m/gR/o7uvNdLqurSkY/5HeDo/rZpMEz0mGGbwT77Wbpvmmuqak4/j95WZQsfdlLzkvwHul+SPGTqyLAfHrgUeHgfsstZ34vpjnSfuMDrPYBueGjUEKV+MXiEL82gHwr4Q7pfufz8yKiqflxVD1uOsO+H1h7bD709jG5IbPJEqzStWQO/v8T4piRfm2F5krwl3X+/XJbkEQtfprS0+jHrW+hO/L5lmcsZ2hl4B91QyqeB/0U3pCLNatYhnf7k3W3Ae6vqkGmWHwO8mG7s8FHAm6vqUYtQqyRpHmY9wq+qi9jyb1GPo/swqKq6GNgryYMWqkBJ0sJYiD+JWsk9L87Y0M+7YbJhkpPpLldm1113feRDH/rQBdi8JLXjy1/+8s1VtWIuj12IwJ/uLP6040RVdSZwJsCaNWtq3bp1C7B5SWpHkjFXu09rIX6ls4F7Xo23is1X40mSthELEfhrgT/of63zaGBTVd1rOEeStLxmHdJJ8gHgCLr/c9lAd6XffQGq6m10VwYeQ/dnSXfQXfYvSdrGzBr4VXXCLMuLe/6fhyRpG+SVtpLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiNGBX6So5JcmWR9ktOmWb5vkguTXJrksiTHLHypkqT5mDXwk+wAnAEcDRwMnJDk4IlmfwqcU1WHAscDb13oQiVJ8zPmCP8wYH1VXVVVdwJnA8dNtClgj/7+nsD1C1eiJGkhjAn8lcB1g+kN/byh1wInJtkAnA+8eLoVJTk5ybok6zZu3DiHciVJczUm8DPNvJqYPgF4d1WtAo4B3pfkXuuuqjOrak1VrVmxYsXWVytJmrMxgb8BWD2YXsW9h2xOAs4BqKovArsA+yxEgZKkhTEm8C8BDkyyf5Kd6E7Krp1ocy3wRIAkD6MLfMdsJGkbMmvgV9VdwCnABcDX6X6Nc3mS05Mc2zc7FXhekq8CHwCeXVWTwz6SpGW045hGVXU+3cnY4bzXDO5fARy+sKVJkhaSV9pKUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJasSowE9yVJIrk6xPctoMbZ6e5Ioklyc5a2HLlCTN146zNUiyA3AG8CRgA3BJkrVVdcWgzYHAHwOHV9UtSR64WAVLkuZmzBH+YcD6qrqqqu4EzgaOm2jzPOCMqroFoKpuWtgyJUnzNSbwVwLXDaY39POGDgIOSvKFJBcnOWq6FSU5Ocm6JOs2btw4t4olSXMyJvAzzbyamN4ROBA4AjgBeGeSve71oKozq2pNVa1ZsWLF1tYqSZqHMYG/AVg9mF4FXD9Nm49W1U+r6mrgSroPAEnSNmJM4F8CHJhk/yQ7AccDayfafAR4AkCSfeiGeK5ayEIlSfMza+BX1V3AKcAFwNeBc6rq8iSnJzm2b3YB8L0kVwAXAq+oqu8tVtGSpK2Xqsnh+KWxZs2aWrdu3bJsW5J+USX5clWtmctjvdJWkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqxKjAT3JUkiuTrE9y2hbaPS1JJVmzcCVKkhbCrIGfZAfgDOBo4GDghCQHT9Nud+AlwJcWukhJ0vyNOcI/DFhfVVdV1Z3A2cBx07R7HfAG4McLWJ8kaYGMCfyVwHWD6Q39vJ9LciiwuqrO29KKkpycZF2SdRs3btzqYiVJczcm8DPNvPr5wuQ+wJuAU2dbUVWdWVVrqmrNihUrxlcpSZq3MYG/AVg9mF4FXD+Y3h04BPhckmuARwNrPXErSduWMYF/CXBgkv2T7AQcD6ydWlhVm6pqn6rar6r2Ay4Gjq2qdYtSsSRpTmYN/Kq6CzgFuAD4OnBOVV2e5PQkxy52gZKkhbHjmEZVdT5w/sS818zQ9oj5lyVJWmheaStJjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEaMCP8lRSa5Msj7JadMsf1mSK5JcluQzSR688KVKkuZj1sBPsgNwBnA0cDBwQpKDJ5pdCqypqt8APgS8YaELlSTNz5gj/MOA9VV1VVXdCZwNHDdsUFUXVtUd/eTFwKqFLVOSNF9jAn8lcN1gekM/byYnAZ+YbkGSk5OsS7Ju48aN46uUJM3bmMDPNPNq2obJicAa4I3TLa+qM6tqTVWtWbFixfgqJUnztuOINhuA1YPpVcD1k42SHAn8CfD4qvrJwpQnSVooY47wLwEOTLJ/kp2A44G1wwZJDgXeDhxbVTctfJmSpPmaNfCr6i7gFOAC4OvAOVV1eZLTkxzbN3sjsBtwbpKvJFk7w+okSctkzJAOVXU+cP7EvNcM7h+5wHVJkhaYV9pKUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNGBX4SY5KcmWS9UlOm2b5zkk+2C//UpL9FrpQSdL8zBr4SXYAzgCOBg4GTkhy8ESzk4BbquoA4E3AXy10oZKk+RlzhH8YsL6qrqqqO4GzgeMm2hwHvKe//yHgiUmycGVKkuZrxxFtVgLXDaY3AI+aqU1V3ZVkE/AA4OZhoyQnAyf3kz9J8rW5FL0d2oeJvmqYfbGZfbGZfbHZr831gWMCf7oj9ZpDG6rqTOBMgCTrqmrNiO1v9+yLzeyLzeyLzeyLzZKsm+tjxwzpbABWD6ZXAdfP1CbJjsCewPfnWpQkaeGNCfxLgAOT7J9kJ+B4YO1Em7XAs/r7TwM+W1X3OsKXJC2fWYd0+jH5U4ALgB2Ad1XV5UlOB9ZV1VrgH4D3JVlPd2R//IhtnzmPurc39sVm9sVm9sVm9sVmc+6LeCAuSW3wSltJaoSBL0mNWPTA928ZNhvRFy9LckWSy5J8JsmDl6POpTBbXwzaPS1JJdluf5I3pi+SPL3fNy5PctZS17hURrxH9k1yYZJL+/fJMctR52JL8q4kN810rVI6b+n76bIkjxi14qpatBvdSd5vAw8BdgK+Chw80eaFwNv6+8cDH1zMmpbrNrIvngDcr7//gpb7om+3O3ARcDGwZrnrXsb94kDgUmDvfvqBy133MvbFmcAL+vsHA9csd92L1BePAx4BfG2G5ccAn6C7BurRwJfGrHexj/D9W4bNZu2Lqrqwqu7oJy+mu+ZhezRmvwB4HfAG4MdLWdwSG9MXzwPOqKpbAKrqpiWucamM6YsC9ujv78m9rwnaLlTVRWz5WqbjgPdW52JgryQPmm29ix340/0tw8qZ2lTVXcDU3zJsb8b0xdBJdJ/g26NZ+yLJocDqqjpvKQtbBmP2i4OAg5J8IcnFSY5asuqW1pi+eC1wYpINwPnAi5emtG3O1uYJMO6vFeZjwf6WYTsw+nkmORFYAzx+UStaPlvsiyT3ofvX1WcvVUHLaMx+sSPdsM4RdN/6Pp/kkKq6dZFrW2pj+uIE4N1V9TdJHkN3/c8hVfWzxS9vmzKn3FzsI3z/lmGzMX1BkiOBPwGOraqfLFFtS222vtgdOAT4XJJr6MYo126nJ27Hvkc+WlU/raqrgSvpPgC2N2P64iTgHICq+iKwC90fq7VmVJ5MWuzA928ZNpu1L/phjLfThf32Ok4Ls/RFVW2qqn2qar+q2o/ufMaxVTXnP43aho15j3yE7oQ+SfahG+K5akmrXBpj+uJa4IkASR5GF/gbl7TKbcNa4A/6X+s8GthUVTfM9qBFHdKpxftbhl84I/vijcBuwLn9eetrq+rYZSt6kYzsiyaM7IsLgN9NcgVwN/CKqvre8lW9OEb2xanAO5K8lG4I49nb4wFikg/QDeHt05+v+HPgvgBV9Ta68xfHAOuBO4DnjFrvdthXkqRpeKWtJDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mN+P/MzF6vgF31IwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x207260e32b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot2DBoundary(model, data_train, label_train, data_test, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting your answers, experiment with using using PCA instead of ISOMap. Are the results what you expected? Also try tinkering around with the test/train split percentage from 10-20%. Notice anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .. your code changes above .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
